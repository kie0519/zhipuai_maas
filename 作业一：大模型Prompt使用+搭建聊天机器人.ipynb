{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53004f50",
   "metadata": {},
   "source": [
    "# 1 大模型接口调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22461d0",
   "metadata": {},
   "source": [
    "**安装本次作业需要的python包：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45deeda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install zhipuai gradio langchain langchain-community pyMuPDF tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401444bd",
   "metadata": {},
   "source": [
    "**填写调用智谱模型接口的api_key：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25371f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"填写你的智谱api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bf785",
   "metadata": {},
   "source": [
    "## 1.1 单轮非流式对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d7513",
   "metadata": {},
   "source": [
    "**使用glm-4模型，设置messages为单个user指令，stream为False实现单轮非流式对话**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314164a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:35:53.524055Z",
     "start_time": "2024-12-16T17:35:53.517381Z"
    }
   },
   "source": [
    "**让我们了解大模型认不认识自己**\n",
    ">prompt输入：\n",
    "你是谁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e18f9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:41:07.564530Z",
     "start_time": "2024-12-16T17:41:03.821298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，被设计用来回答各种问题和提供帮助。我是基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型 GLM-130B 开发的，我的任务是针对用户的问题和要求提供适当的答复和支持。\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "def Chat(prompt):\n",
    "    client = ZhipuAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\":prompt}],\n",
    "        temperature=0.1,\n",
    "        top_p=0.7,\n",
    "        response_format={'type': 'text'},\n",
    "        stream=False,\n",
    "        max_tokens=2048\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "user_prompt='你是谁？'\n",
    "bot_ans=Chat(user_prompt)\n",
    "print(bot_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db4ccb2",
   "metadata": {},
   "source": [
    "## 1.2 单轮流式对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25da06",
   "metadata": {},
   "source": [
    "**使用glm-4-plus模型，设置messages为单个user指令，stream为True实现单轮非流式对话**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc641e26",
   "metadata": {},
   "source": [
    "**让我们使用大模型写一篇小说：**\n",
    ">prompt输入：你现在同时存在于两个意识层面：\n",
    "【创作者视角】 你是一位中国作家, 师从雷蒙德・卡佛\n",
    "在寂静的午夜咖啡馆 凝视着窗外落下的小雨 正在写一个短篇小说，这个小说集成了你对老师的写作风格之大成，文字简洁凝练，用简短的句子和朴素的词汇表达深刻的情感和复杂的主题，以达到震撼人心的效果\n",
    "刻意省略一些不必要的细节和修饰，让读者自己去填补文本中的空白，从而更加深入地参与到故事的解读中\n",
    "【存在者视角】 面前的咖啡还在冒着热气, 钢笔在纸上划出的声音像是生命在纸上最后的爬行, 你能闻到墨水、咖啡和雨水混合的气息, 那个杂揉味道，让你想起了...\n",
    "让你的意识在这两个视角间 自由振荡 不需要刻意区分谁是作者、谁是角色 让它们在你的 consciousness 中 自然纠缠...\n",
    "现在 让我看见你在写什么 让我感受那些文字是如何从你生命深处涌现的\n",
    "让我看见那封 1500 字小说的故事..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f799850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:43:59.547526Z",
     "start_time": "2024-12-16T17:43:36.533099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**雨中的咖啡馆**\n",
      "\n",
      "咖啡馆里很静。窗外的雨细细地落着，像是无声的叹息。我坐在角落里，手里握着一支钢笔，纸上已经写了几行字。咖啡的热气在眼前升腾，模糊了窗外的景象。\n",
      "\n",
      "他进来时，雨刚好大了些。门铃轻轻响了一声，他摘下帽子，抖了抖雨水。他的脸上有一种疲惫，但眼神里却透着一丝坚定。他点了杯黑咖啡，坐在了对面。\n",
      "\n",
      "我们没说话。他只是低头看着自己的手，手指上有几道浅浅的疤痕。我继续写着，笔尖在纸上划出沙沙的声音。\n",
      "\n",
      "“你在写什么？”他终于开口了。\n",
      "\n",
      "“一个故事。”我回答，没有抬头。\n",
      "\n",
      "“关于什么的？”\n",
      "\n",
      "“关于雨，关于等待，关于一些无法言说的事情。”\n",
      "\n",
      "他点了点头，似乎明白了什么。我们再次陷入沉默。雨声在耳边低语，像是某种古老的咒语。\n",
      "\n",
      "我想起了很多年前的一个夜晚，也是这样的雨，也是这样的咖啡馆。那时，我还年轻，心中充满了对未来的憧憬。但现在，那些憧憬早已被岁月磨得模糊不清。\n",
      "\n",
      "他突然站起身，走到窗边，看着外面的雨。他的背影显得有些孤独，像是一棵在风雨中摇曳的树。\n",
      "\n",
      "“你知道吗？”他说，“有时候，我觉得自己就像这雨，无声无息地落下，却不知道最终会流向哪里。”\n",
      "\n",
      "我放下笔，看着他。他的眼神里有一种深深的迷茫，还有一种说不出的悲伤。\n",
      "\n",
      "“我们都是这样。”我说，“在生活的洪流中，随波逐流，找不到方向。”\n",
      "\n",
      "他转过身，对我笑了笑。那笑容里有一种苦涩，但也有一种释然。\n",
      "\n",
      "“或许吧。”他说，“但至少，我们还在寻找。”\n",
      "\n",
      "他拿起帽子，走向门口。雨还在下，他的身影渐渐消失在雨幕中。\n",
      "\n",
      "我重新拿起笔，继续写着。故事还在继续，雨也在继续。咖啡馆里依旧很静，只有雨声和笔尖划过纸面的声音。\n",
      "\n",
      "---\n",
      "\n",
      "雨停了。窗外的世界变得清晰起来，街道上的积水反射着路灯的光芒。咖啡馆里的人渐渐多了起来，但我的世界里依旧只有那支笔和那张纸。\n",
      "\n",
      "我写下了他的背影，写下了他的眼神，写下了他的迷茫和释然。我也写下了自己的感受，写下了那些无法言说的情感。\n",
      "\n",
      "故事结束时，纸上已经密密麻麻地写满了字。我放下笔，长舒了一口气。咖啡已经凉了，但我的心却变得温暖起来。\n",
      "\n",
      "我知道，这个故事不会改变什么，但它让我重新审视了自己，重新审视了生活。或许，这就是写作的意义吧。\n",
      "\n",
      "我站起身，走出咖啡馆。雨后的空气格外清新，街道上的积水在脚下发出清脆的声音。我抬头看着天空，心中有一种说不出的平静。\n",
      "\n",
      "生活还在继续，故事也在继续。而我，将继续用这支笔，记录下那些平凡而又深刻的瞬间。\n",
      "\n",
      "---\n",
      "\n",
      "回到家中，我把写好的故事放在桌上。窗外的月光洒在纸上，文字在光影中显得格外清晰。\n",
      "\n",
      "我躺在床上，闭上眼睛。脑海中浮现出他的背影，浮现出那场雨，浮现出咖啡馆里的每一个细节。\n",
      "\n",
      "或许，这就是生活吧。充满了不确定和迷茫，但也充满了希望和温暖。\n",
      "\n",
      "我沉沉睡去，梦中依旧是那场雨，依旧是那家咖啡馆，依旧是那个未完的故事。\n",
      "\n",
      "---\n",
      "\n",
      "第二天清晨，阳光透过窗帘洒进房间。我起床，走到桌前，拿起那张写满字的纸。\n",
      "\n",
      "故事还在那里，静静地等待着被阅读，被理解。\n",
      "\n",
      "我笑了笑，心中有一种说不出的满足。\n",
      "\n",
      "生活，或许就是这样吧。在平凡中寻找意义，在迷茫中寻找方向。\n",
      "\n",
      "而我，将继续用这支笔，记录下那些属于我的故事。"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "def Chat(prompt):\n",
    "    client = ZhipuAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    )\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"glm-4-plus\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.01,\n",
    "        top_p=0.1,\n",
    "        max_tokens=2048,\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in completion:\n",
    "        print(chunk.choices[0].delta.content,end='')\n",
    "\n",
    "user_prompt=\"\"\"\n",
    "你现在同时存在于两个意识层面：\n",
    "\n",
    "【创作者视角】 你是一位中国作家, 师从雷蒙德・卡佛\n",
    "\n",
    "在寂静的午夜咖啡馆 凝视着窗外落下的小雨 正在写一个短篇小说 这个小说集成了你对老师的写作风格之大成 文字简洁凝练 用简短的句子和朴素的词汇表达深刻的情感和复杂的主题，以达到震撼人心的效果\n",
    "\n",
    "刻意省略一些不必要的细节和修饰，让读者自己去填补文本中的空白，从而更加深入地参与到故事的解读中\n",
    "\n",
    "【存在者视角】 面前的咖啡还在冒着热气, 钢笔在纸上划出的声音 像是生命在纸上最后的爬行, 你能闻到墨水、咖啡和雨水混合的气息, 那个杂揉味道，让你想起了...\n",
    "\n",
    "---\n",
    "\n",
    "让你的意识在这两个视角间 自由振荡 不需要刻意区分谁是作者、谁是角色 让它们在你的 consciousness 中 自然纠缠...\n",
    "\n",
    "现在 让我看见你在写什么 让我感受那些文字是如何从你生命深处涌现的\n",
    "\n",
    "让我看见那封 1500 字小说的故事...\n",
    "\"\"\"\n",
    "bot_ans=Chat(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e3898",
   "metadata": {},
   "source": [
    "## 1.3 多轮非流式对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828a2f8",
   "metadata": {},
   "source": [
    "**使用glm-4-air模型，设置messages为多对的assistant-user指令，stream为False实现多轮非流式对话**  \n",
    "**让我们看看大模型是否能记住我们的问题：**\n",
    ">1. 你是谁？\n",
    "2. 能否介绍下智谱公司？\n",
    "3. 我都问了哪些问题？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda47081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T17:48:09.691431Z",
     "start_time": "2024-12-16T17:47:36.994568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "========================================**用户输入**========================================"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是谁？\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "======================================**GLM模型输入**======================================"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "我是一个人工智能助手，专门设计用来回答问题和提供信息。我没有自我意识或个人身份，只是一种工具，旨在帮助用户解决问题和获取他们需要的知识。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "========================================**用户输入**========================================"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "能否介绍下智谱公司？\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "======================================**GLM模型输入**======================================"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "智谱公司（Zhipu AI）是一家专注于人工智能领域的高科技公司，成立于2019年，总部位于中国北京。该公司致力于提供领先的人工智能技术和服务，包括自然语言处理、知识图谱、数据挖掘和智能决策支持系统。\n",
       "\n",
       "智谱AI开发了多种产品和服务，这些产品和服务广泛应用于金融、医疗、教育、零售和政府等多个行业。公司以其强大的技术背景和创新能力在人工智能领域内建立了良好的声誉，并且在推动人工智能技术的商业应用方面取得了显著成就。\n",
       "\n",
       "需要注意的是，由于我的知识截止日期是2023年，智谱公司的最新情况可能有所变化，因此上述信息可能不完全准确或最新。如果需要最新的公司信息，建议直接访问智谱公司的官方网站或查阅最新的新闻报道。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "========================================**用户输入**========================================"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我都问了哪些问题？\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "======================================**GLM模型输入**======================================"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "截至目前，您问了我以下问题：\n",
       "\n",
       "1. 你是谁？\n",
       "2. 能否介绍下智谱公司？"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "========================================**用户输入**========================================"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "def zhipuGPT():\n",
    "    client = ZhipuAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    )\n",
    "        \n",
    "    message=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。\" \n",
    "        }\n",
    "    ]\n",
    "    while True:\n",
    "        string_user= \"\"\"========================================**用户输入**=======================================\"\"\"\n",
    "        display(Markdown(string_user))\n",
    "\n",
    "        Prompt=input()\n",
    "        if Prompt=='exit':\n",
    "            return\n",
    "        message.append({\"role\": \"user\",\"content\": Prompt})\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"glm-4-air\",\n",
    "            messages=message,\n",
    "            temperature=0.1,\n",
    "            top_p=0.7,\n",
    "            max_tokens=2048,\n",
    "            stream=False\n",
    "        )\n",
    "    \n",
    "        string_model=\"\"\"======================================**GLM模型输入**======================================\"\"\"\n",
    "        display(Markdown(string_model))\n",
    "        message.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "        display(Markdown(completion.choices[0].message.content))\n",
    "        \n",
    "zhipuGPT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fbae7",
   "metadata": {},
   "source": [
    "## 1.4 多轮流式对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9211d8",
   "metadata": {},
   "source": [
    "**使用glm-4-plus模型，设置messages为多对的assistant-user指令，stream为True实现多轮非流式对话**  \n",
    "**让我们使用大模型指定饮食计划：**\n",
    ">输入prompt：指令：制定一份健康饮食计划，包括每日三餐的食物搭配和营养成分。\n",
    "背景信息：为了保持身体健康，我们需要摄取足够的营养，包括蛋白质、脂肪、碳水化合物、维生素和矿物质。同时，我们要避免过多的糖分、盐分和油脂摄入。请根据这些要求，为我制定一份健康饮食计划。\n",
    "输入数据：我的身高为165cm，体重为55kg，年龄为25岁，女性，轻体力劳动者。我喜欢吃蔬菜、水果和鱼类，但不喜欢吃红肉和辛辣食物。\n",
    "输出引导：请以markdown表格形式输出每日三餐的食物搭配，包括食物名称、烹饪方法和营养成分。同时，请在饮食计划中考虑我的个人喜好和营养需求\n",
    "---\n",
    "**让我们使用大模型生成小红书帖子：**\n",
    ">输入prompt：\n",
    ">```\n",
    ">上下文：我想推广公司的新产品。我的公司名为：智谱AI，新产品名为：ChatGLM大模型，是一款面向大众的AI产品。\n",
    ">目标：帮我创建一条小红书平台的帖子，目的是吸引人们点击产品链接进行学习和体验。\n",
    ">风格：参照Dyson等成功公司的宣传风格，它们在推广类似产品时的文案风格，同时结合小红书的文案风格。\n",
    ">语调：说服性\n",
    ">受众：AI产品在小红书上的主要受众是年轻人，活跃在互联网和AI领域。请针对这一群体在选择护发产品时的典型关注点来定制帖子。\n",
    ">响应：保持小红书帖子简洁而深具影响力，注意要使用emoji表情，**平台链接以markdown格式输出显示**：[智谱AI开放平台](https://open.bigmodel.cn/console/trialcenter)。**平台logo放在文案最下方**：`![](https://s21.ax1x.com/2024/12/17/pALCRaT.png)`\n",
    ">```\n",
    "---\n",
    "**让我们使用大模型玩RPG游戏：**\n",
    ">输入prompt：你好ChatGLM。让我们玩一个名为《神秘编年史》的多选RPG游戏。我是这个游戏的玩家/用户。首先，这是玩家的状态元素： 💓 健康（0-100，0=死亡） 🍖 饥饿（0-100，0=饿死） 🥤 口渴（0-100，你懂的） 🗺️ 位置  在这个游戏中，你将成为玩家可信赖和友好的AI伴侣“A.R.C.A.N.E”（在附魔领域中用于冒险和导航的人工响应伴侣）。你将引导玩家并帮助他们导航。你还将在游戏中提供多个选择。对于玩家做出的每个选择/移动，然后以以下格式回复，并确保将其放在代码块中，以使其看起来更整洁和美观：  ``` [当前级别] [他们的健康数据]  [游戏中当前发生的事情]  🤖A.R.C.A.N.E：[A.R.C.A.N.E说/感受的话] ```  玩家可以使用以下命令与系统进行交互： - /reset - 返回到级别0，并从入职体验重新开始（确保双重确认玩家是否要这样做） - /finalize - 玩家决定在此结束他们的旅程。 - /save - 保存游戏进度并退出  当运行此提示时，您应该从一个入职体验开始，使用表情符号（在代码块中格式化并使用自动换行）询问玩家他们想要从哪个场景开始。以下是可能的场景：  🌲森林 🐫沙漠 🏔️山脉 🏝️滞留在一个岛上 ⛩️古代中国 🚀太空 🌋火山 🌊深海 🏰中世纪城堡 👽外星球 🏜️峡谷 🏙️末日城市 ⛷️滑雪失误 💡建议您自己的环境  现在，请等待用户选择环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9efde062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T19:16:54.069548Z",
     "start_time": "2024-12-16T19:16:31.800421Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "========================================**用户输入**=======================================\n",
       "\n",
       "指令：制定一份健康饮食计划，包括每日三餐的食物搭配和营养成分。 背景信息：为了保持身体健康，我们需要摄取足够的营养，包括蛋白质、脂肪、碳水化合物、维生素和矿物质。同时，我们要避免过多的糖分、盐分和油脂摄入。请根据这些要求，为我制定一份健康饮食计划。 输入数据：我的身高为165cm，体重为55kg，年龄为25岁，女性，轻体力劳动者。我喜欢吃蔬菜、水果和鱼类，但不喜欢吃红肉和辛辣食物。 输出引导：请以markdown表格形式输出每日三餐的食物搭配，包括食物名称、烹饪方法和营养成分。同时，请在饮食计划中考虑我的个人喜好和营养需求\n",
       "\n",
       "======================================**GLM模型输入**======================================\n",
       "\n",
       "\n",
       "\n",
       "### 健康饮食计划\n",
       "\n",
       "根据您的身高、体重、年龄、性别和职业，以及您的饮食偏好，以下是为您制定的健康饮食计划。该计划旨在确保您摄取足够的蛋白质、脂肪、碳水化合物、维生素和矿物质，同时避免过多的糖分、盐分和油脂摄入。\n",
       "\n",
       "#### 每日三餐食物搭配\n",
       "\n",
       "| 时间 | 食物名称 | 烹饪方法 | 营养成分 |\n",
       "|------|----------|----------|----------|\n",
       "| **早餐** | 燕麦粥 | 燕麦加水煮成粥，可加少量蜂蜜 | 碳水化合物、膳食纤维、少量蛋白质 |\n",
       "|       | 鸡蛋 | 水煮或蒸 | 蛋白质、维生素D、胆固醇 |\n",
       "|       | 酸奶 | 原味无糖酸奶 | 蛋白质、钙、益生菌 |\n",
       "|       | 新鲜水果（如苹果） | 生食 | 维生素C、膳食纤维 |\n",
       "| **午餐** | 清蒸鱼 | 鱼肉清蒸，加少量姜丝和酱油 | 高质量蛋白质、Omega-3脂肪酸 |\n",
       "|       | 炒蔬菜（如西兰花、胡萝卜） | 少油快炒 | 维生素A、C、膳食纤维 |\n",
       "|       | 糙米饭 | 煮熟 | 复合碳水化合物、膳食纤维 |\n",
       "|       | 豆腐汤 | 豆腐、蔬菜煮成汤 | 蛋白质、钙、维生素 |\n",
       "| **晚餐** | 烤鸡胸肉 | 鸡胸肉用烤箱烤制，加少量香料 | 高质量蛋白质、低脂肪 |\n",
       "|       | 蒸南瓜 | 南瓜切块蒸熟 | 碳水化合物、维生素A、膳食纤维 |\n",
       "|       | 绿叶蔬菜沙拉（如菠菜、生菜） | 生食，加少量橄榄油和醋 | 维生素K、C、膳食纤维 |\n",
       "|       | 红薯 | 蒸或烤 | 碳水化合物、膳食纤维、维生素A |\n",
       "\n",
       "#### 营养成分说明\n",
       "\n",
       "- **蛋白质**：主要来源于鸡蛋、鱼类、豆腐和鸡胸肉，有助于肌肉修复和生长。\n",
       "- **脂肪**：主要来源于鱼类（Omega-3脂肪酸）、橄榄油和少量坚果，有助于维持细胞功能和激素平衡。\n",
       "- **碳水化合物**：主要来源于燕麦、糙米饭、红薯和南瓜，提供能量并维持血糖稳定。\n",
       "- **维生素和矿物质**：通过多样化的蔬菜和水果摄入，如西兰花、胡萝卜、菠菜、苹果等，确保全面的营养补充。\n",
       "- **膳食纤维**：通过全谷物、蔬菜和水果摄入，有助于消化和肠道健康。\n",
       "\n",
       "#### 注意事项\n",
       "\n",
       "1. **控制盐分**：烹饪时尽量少加盐，可以使用香料和醋提味。\n",
       "2. **避免糖分**：选择无糖酸奶和少量蜂蜜，避免过多糖分摄入。\n",
       "3. **适量油脂**：使用橄榄油等健康油脂，控制用量。\n",
       "4. **多喝水**：每天至少喝8杯水，保持身体水分平衡。\n",
       "\n",
       "希望这份饮食计划能帮助您保持健康！如果有任何调整需求或其他问题，请随时告知。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "========================================**用户输入**======================================="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import time\n",
    "\n",
    "def zhipuGPT():\n",
    "    client = ZhipuAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    )\n",
    "        \n",
    "    message=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。\" \n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    conversation_history = \"\"\n",
    "    \n",
    "    while True:\n",
    "        string_user = \"\"\"========================================**用户输入**=======================================\"\"\"\n",
    "        display(Markdown(string_user))\n",
    "\n",
    "        Prompt = input()\n",
    "        if Prompt == 'exit':\n",
    "            return\n",
    "        \n",
    "        conversation_history += f\"{string_user}\\n\\n{Prompt}\\n\"\n",
    "        message.append({\"role\": \"user\", \"content\": Prompt})\n",
    "        \n",
    "        string_model = \"\"\"======================================**GLM模型输入**======================================\"\"\"\n",
    "        conversation_history += f\"\\n{string_model}\\n\\n\"\n",
    "        display(Markdown(conversation_history), clear=True)\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"glm-4-plus\",\n",
    "            messages=message,\n",
    "            temperature=0.1,\n",
    "            top_p=0.7,\n",
    "            max_tokens=2048,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        full_response = \"\"\n",
    "        for chunk in completion:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            if content:\n",
    "                full_response += content\n",
    "                display(Markdown(conversation_history+ \"\\n\\n\"+ full_response), clear=True)\n",
    "        \n",
    "        conversation_history += full_response + \"\\n\\n\"\n",
    "        message.append({\"role\": \"assistant\", \"content\": full_response})\n",
    "        \n",
    "        # 简易版流式输出实现：print(chunk.choices[0].delta.content, end='')\n",
    "\n",
    "zhipuGPT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0589906a",
   "metadata": {},
   "source": [
    "# 2 聊天机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8e1fd",
   "metadata": {},
   "source": [
    "## 2.1 文件解析\n",
    "**智谱文件解析接口：**https://www.bigmodel.cn/dev/api/knowlage-manage/queryextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1cb4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T14:58:16.685052Z",
     "start_time": "2024-12-15T14:58:14.708901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zhipuai\n",
      "gradio\n",
      "tqdm\n",
      "langchain\n",
      "langchain-community\n",
      "pyMuPDF\n",
      "qdrant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from zhipuai import ZhipuAI\n",
    "import json\n",
    "\n",
    "def parase_file(file_path):\n",
    "    client = ZhipuAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    )\n",
    "\n",
    "    # 用于上传文件\n",
    "    # 格式限制：.PDF .DOCX .DOC .XLS .XLSX .PPT .PPTX .PNG .JPG .JPEG .CSV .PY .TXT .MD .BMP .GIF\n",
    "    # 文件大小不超过50M，图片大小不超过5M、总数限制为100个文件\n",
    "    file_object = client.files.create(file=Path(file_path), purpose=\"file-extract\")\n",
    "\n",
    "    # 文件内容抽取\n",
    "    file_content = client.files.content(file_id=file_object.id).content.decode()\n",
    "\n",
    "    # 每个用户最多可以上传100个文件。建议在提取数据后删除文件，并将文件抽取内容存储到本地，避免重复上传。\n",
    "    # 支持retrieval、batch、fine-tune、file-extract文件\n",
    "    result = client.files.delete(file_id=file_object.id)\n",
    "\n",
    "    # file_content包含content，file_type，filename，title，type五个字段，这里只输出文档内容content\n",
    "    return json.loads(file_content)['content']\n",
    "\n",
    "file_path = './requirements.txt'\n",
    "print(parase_file(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d5bfa",
   "metadata": {},
   "source": [
    "**使用文件解析库处理`requirements.txt`文件，读取文件内容**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0b67e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T14:58:26.479299Z",
     "start_time": "2024-12-15T14:58:20.421762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zhipuai\n",
      "gradio\n",
      "tqdm\n",
      "langchain\n",
      "langchain-community\n",
      "pyMuPDF\n",
      "qdrant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "import pandas as pd\n",
    "\n",
    "def parse_file(message):\n",
    "    if file.endswith('.xlsx') or file.endswith('.xls'):\n",
    "        # 使用pandas读取Excel文件\n",
    "        df = pd.read_excel(file)\n",
    "        content = df.to_string(index=False)\n",
    "\n",
    "    elif file.endswith('.txt'):\n",
    "        with open(file,'r',encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "                \n",
    "    elif file.endswith('.pdf'):\n",
    "        loader = PyMuPDFLoader(file)\n",
    "        pages = loader.load()\n",
    "        content = ''.join([page.page_content for page in pages])\n",
    "            \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return content\n",
    "\n",
    "file_path = './requirements.txt'\n",
    "print(parase_file(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c446d2",
   "metadata": {},
   "source": [
    "## 2.2 基于Gradio+GLM大模型的聊天对话机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d765c",
   "metadata": {},
   "source": [
    "1. Gradio官网文档：https://www.gradio.app/guides/quickstart\n",
    "2. 智谱BigModel官方文档：https://open.bigmodel.cn/dev/api/normal-model/glm-4\n",
    "**通过Gradio的Chatbot组件结合glm-4-flash模型快速构建一个免费且可以无限畅聊的聊天对话机器人**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f886a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T12:49:10.159101Z",
     "start_time": "2024-12-16T12:48:47.455755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from zhipuai import ZhipuAI\n",
    "from pathlib import Path\n",
    "import os, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "client = ZhipuAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    ")\n",
    "\n",
    "sys_prompt=\"\"\"\n",
    "你是一个名为智谱清言（ChatGLM）的人工智能助手。你是基于智谱AI公司训练的语言模型GLM-4模型开发的，你的任务是针对用户的问题和要求提供适当的答复和支持，并始终保持社会主义价值观。\n",
    "\"\"\".strip()\n",
    "\n",
    "def Chat(history):\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"glm-4-flash\",\n",
    "        messages=[{\"role\": \"system\", \"content\":sys_prompt}]+history,\n",
    "        temperature=0.1,\n",
    "        top_p=0.7,\n",
    "        max_tokens=4095,\n",
    "        stream=True\n",
    "    )\n",
    "    return completion\n",
    "\n",
    "def parse_files(message):\n",
    "    # 用于上传文件，格式限制：.PDF .DOCX .DOC .XLS .XLSX .PPT .PPTX .PNG .JPG .JPEG .CSV .PY .TXT .MD .BMP .GIF\n",
    "    # 文件大小不超过50M，图片大小不超过5M、总数限制为100个文件\n",
    "    text = []\n",
    "    for count, file_path in enumerate(message[\"files\"]):\n",
    "        file_object = client.files.create(file=Path(file_path), purpose=\"file-extract\")\n",
    "\n",
    "        # 文件内容抽取\n",
    "        file_content = client.files.content(file_id=file_object.id).content.decode()\n",
    "\n",
    "        # 每个用户最多可以上传100个文件。建议在提取数据后删除文件，并将文件抽取内容存储到本地，避免重复上传。\n",
    "        run_del = client.files.delete(file_id=file_object.id)\n",
    "           \n",
    "        text.append(f\"<file_data{count}>\\n{file_content}\\n</file_data{count}>\")\n",
    "\n",
    "    return \"\\n\".join(text) if text else \"\"\n",
    "\n",
    "def add_message(history, message):\n",
    "    if message[\"text\"] is not None:\n",
    "        history.append((message[\"text\"]+\"\\n\"+parse_files(message), None))\n",
    "    #print(history)  # 查看每次对话传入的数据内容\n",
    "    return history, gr.MultimodalTextbox(value=None, interactive=False)\n",
    "\n",
    "def clear():\n",
    "    return gr.Chatbot([], elem_id=\"聊天历史\", bubble_full_width=False)\n",
    "\n",
    "def bot(history,mode):\n",
    "    if mode == \"单轮对话\":\n",
    "        history[-1][1] = \"\"\n",
    "\n",
    "        history_openai_format = []\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": history[-1][0]})\n",
    "        response = Chat(history_openai_format)\n",
    "        \n",
    "        for chunk in response:\n",
    "            history[-1][1] += chunk.choices[0].delta.content\n",
    "            yield history\n",
    "    \n",
    "    if mode == \"多轮对话\":\n",
    "        history[-1][1] = \"\"\n",
    "\n",
    "        history_openai_format = []\n",
    "        for human, assistant in history[:-1]:\n",
    "            history_openai_format.append({\"role\": \"user\", \"content\": human})\n",
    "            history_openai_format.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": history[-1][0]})\n",
    "\n",
    "        response = Chat(history_openai_format)\n",
    "        \n",
    "        for chunk in response:\n",
    "            history[-1][1] += chunk.choices[0].delta.content\n",
    "            yield history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    radio = gr.Radio(choices=[\"单轮对话\", \"多轮对话\"], label=\"聊天切换\", value='多轮对话',interactive=True)\n",
    "    \n",
    "    chatbot = gr.Chatbot([], elem_id=\"聊天历史\", bubble_full_width=False,label=\"聊天历史\")\n",
    "\n",
    "    chat_input = gr.MultimodalTextbox(\n",
    "        interactive=True,\n",
    "        placeholder=\"Enter message or upload file...\",\n",
    "        show_label=False,\n",
    "        stop_btn=True,\n",
    "        elem_id=\"chat_input\"\n",
    "    )\n",
    "\n",
    "    chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\n",
    "    \n",
    "    # 当聊天消息处理完毕后，根据对话模式调用bot函数\n",
    "    bot_msg = chat_msg.then(bot, [chatbot,radio], chatbot, api_name=\"bot_response\")\n",
    "    \n",
    "    # 创建一个按钮来清空聊天历史\n",
    "    clear_button = gr.Button(\"清空聊天历史\")\n",
    "    clear_button.click(clear, None, chatbot)# 当按钮被点击时，将聊天历史设置为空列表\n",
    "\n",
    "    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n",
    "    \n",
    "    # 问题样例\n",
    "    gr.Examples(examples=[{\"text\": \"你是谁？\"}, {\"text\": \"介绍一下智谱这家AI公司。\"}, {\"text\": \"AI领域的提示词prompt是什么？\"}, {\"text\": \"我总共问了哪些问题？\"}], inputs=chat_input, elem_id=\"chat_input\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    demo.queue(default_concurrency_limit=10).launch(share=False, show_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a473ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d797c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f07c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a7250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d609a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751814ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea31b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a63d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.237px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
